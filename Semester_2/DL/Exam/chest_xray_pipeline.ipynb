{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chest X‑Ray Pneumonia Classification\n",
    "\n",
    "\n",
    "\n",
    "EDA → Baseline CNN → Transfer‑Learning MobileNetV2\n",
    "\n",
    "\n",
    "\n",
    "> **Dataset:** [Chest X‑Ray Images (Pneumonia)](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia) – ≈5 800 JPEGs split into train/val/test and classes **NORMAL / PNEUMONIA**.\n",
    "\n",
    ">\n",
    "\n",
    "> **Goal:** build a baseline CNN ≤1 M params and an improved model (transfer‑learning) that beats it by ≥ 5 % ROC‑AUC.\n",
    "\n",
    ">\n",
    "\n",
    "> **Author:** *Katrin Pochtar* – June 2025."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0  Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, random, zipfile, warnings, math\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, GlobalAveragePooling2D,\n",
    "                                     Flatten, Dense, Dropout, BatchNormalization)\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import (classification_report, roc_auc_score, roc_curve,\n",
    "                             confusion_matrix, precision_score, recall_score, f1_score)\n",
    "\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep the full dataset by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ZIP = \"chest-xray-pneumonia.zip\"\n",
    "DATA_DIR = Path(\"data\")\n",
    "TRAIN_DIR = DATA_DIR / \"train\"\n",
    "VAL_DIR   = DATA_DIR / \"val\"\n",
    "TEST_DIR  = DATA_DIR / \"test\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1  Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_distribution(split_dir: Path):\n",
    "    counts = {cls: len(list((split_dir / cls).iterdir())) for cls in [\"NORMAL\", \"PNEUMONIA\"]}\n",
    "    return pd.Series(counts, name=split_dir.name)\n",
    "\n",
    "distrib = pd.concat([\n",
    "    class_distribution(TRAIN_DIR),\n",
    "    class_distribution(VAL_DIR),\n",
    "    class_distribution(TEST_DIR)\n",
    "], axis=1)\n",
    "\n",
    "distrib.T.plot(kind=\"bar\", figsize=(6,3), rot=0, title=\"Class balance per split\");\n",
    "plt.ylabel(\"images\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation.** Severe imbalance: *PNEUMONIA* ≈ 3× *NORMAL* in train; we therefore report ROC‑AUC & F1 in addition to Accuracy and will monitor Recall closely.\n",
    "\n",
    "\n",
    "\n",
    "### Atypical / Low‑quality examples\n",
    "\n",
    "We flag blurry images via the variance‑of‑Laplacian heuristic (< 50) and visualise a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_of_laplacian(img):\n",
    "    return cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "\n",
    "def plot_blurry(split_dir, cls, n=5, thresh=50):\n",
    "    imgs = list((split_dir/cls).iterdir())\n",
    "    blurry = [p for p in imgs if variance_of_laplacian(cv2.imread(str(p), 0)) < thresh]\n",
    "    sel = random.sample(blurry, min(n, len(blurry)))\n",
    "    if not sel: return\n",
    "    plt.figure(figsize=(15,3));\n",
    "    for i,p in enumerate(sel,1):\n",
    "        plt.subplot(1,len(sel), i); plt.imshow(Image.open(p), cmap=\"gray\"); plt.axis(\"off\")\n",
    "    plt.suptitle(f\"Potentially blurry {cls} images (n={len(blurry)})\")\n",
    "    plt.show()\n",
    "\n",
    "plot_blurry(TRAIN_DIR, \"NORMAL\"); plot_blurry(TRAIN_DIR, \"PNEUMONIA\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision:** We keep all images (to preserve sample size) and rely on augmentation + model robustness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2  Data Pipeline\n",
    "\n",
    "Because the official val/ folder holds only 16 images, we instead carve out a validation set from the training data using validation_split = 0.15. This gives the model a more representative sample for early stopping and hyper‑parameter tuning.\n",
    "\n",
    "* 224 × 224 resize  \n",
    "\n",
    "* Pixel scale to [‑1, 1] (rescale=1/127.5‑1)  \n",
    "\n",
    "* Augmentations (≥ 3): rotation ±10°, width/height shift 10 %, horizontal flip off (lungs are not bilaterally symmetric for pathology), zoom 10 %, brightness 0.8–1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_IMAGES = int(os.getenv(\"MAX_IMAGES\", \"0\"))  # 0 = use all\n",
    "\n",
    "# normalise images to [-1, 1] range\n",
    "def to_minus1_plus1(x):\n",
    "    \"\"\"Convert uint8 [0‥255] → float32 [-1‥1].\"\"\"\n",
    "    return x / 127.5 - 1.0\n",
    "\n",
    "# data generators\n",
    "a_train = ImageDataGenerator(\n",
    "    preprocessing_function=to_minus1_plus1,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    validation_split=0.15,\n",
    "    horizontal_flip=False,   # flips are unsafe for chest X-rays\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "a_test = ImageDataGenerator(\n",
    "    preprocessing_function=to_minus1_plus1\n",
    ")\n",
    "\n",
    "common_args = dict(target_size=(224, 224),\n",
    "                   batch_size=32,\n",
    "                   class_mode=\"binary\")\n",
    "\n",
    "def flow_limited(datagen, directory, subset=None):\n",
    "    gen = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        subset=subset,\n",
    "        shuffle=(subset == \"training\"),\n",
    "        **common_args\n",
    "    )\n",
    "    return gen\n",
    "\n",
    "train_gen = flow_limited(a_train, TRAIN_DIR, subset=\"training\")\n",
    "val_gen   = flow_limited(a_train, TRAIN_DIR, subset=\"validation\")\n",
    "test_gen  = a_test.flow_from_directory(TEST_DIR,\n",
    "                                       shuffle=False,\n",
    "                                       **common_args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3  Utility – Metric Printer & Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def print_metrics(name, y_true, y_prob):\n",
    "    y_pred = (y_prob > 0.5).astype(int)\n",
    "    metrics = OrderedDict([\n",
    "        (\"Accuracy\",      np.mean(y_pred==y_true)),\n",
    "        (\"Precision\",     precision_score(y_true, y_pred)),\n",
    "        (\"Recall\",        recall_score(y_true, y_pred)),\n",
    "        (\"F1\",            f1_score(y_true, y_pred)),\n",
    "        (\"ROC_AUC\",       roc_auc_score(y_true, y_prob))\n",
    "    ])\n",
    "    print(f\"\\n{name}\")\n",
    "    for k,v in metrics.items():\n",
    "        print(f\"{k:>9}: {v:.3f}\")\n",
    "    return metrics\n",
    "\n",
    "def roc_plot(y_true, y_prob, label):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    plt.plot(fpr, tpr, label=label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4  Baseline – Simple CNN (≤ 1 M parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Sequential([\n",
    "    Conv2D(32, 3, activation=\"relu\", input_shape=(224,224,3)),\n",
    "    MaxPooling2D(2),\n",
    "\n",
    "    Conv2D(64, 3, activation=\"relu\"),\n",
    "    MaxPooling2D(2),\n",
    "\n",
    "    Conv2D(128, 3, activation=\"relu\"),\n",
    "    MaxPooling2D(2),\n",
    "\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dropout(0.5, seed=SEED),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "baseline.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "baseline.summary()\n",
    "\n",
    "hist_base = baseline.fit(train_gen, epochs=15, validation_data=val_gen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves – baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(hist_base.history['accuracy'], label='train acc')\n",
    "plt.plot(hist_base.history['val_accuracy'], label='val acc')\n",
    "plt.title('Baseline accuracy per epoch')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(hist_base.history['loss'], label='train loss')\n",
    "plt.plot(hist_base.history['val_loss'], label='val loss')\n",
    "plt.title('Baseline loss per epoch')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_test = test_gen.classes\n",
    "probs_base  = baseline.predict(test_gen, verbose=0)\n",
    "metrics_base = print_metrics(\"Baseline\", y_true_test, probs_base)\n",
    "\n",
    "# ROC curve\n",
    "plt.figure(figsize=(5,5))\n",
    "roc_plot(y_true_test, probs_base, f\"Baseline AUC = {metrics_base['ROC_AUC']:.3f}\")\n",
    "plt.plot([0,1],[0,1],'k--'); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC curve\"); plt.legend(); plt.show()\n",
    "\n",
    "# Confusion matrix\n",
    "conf_base = confusion_matrix(y_true_test, (probs_base>0.5).astype(int))\n",
    "sns.heatmap(conf_base, annot=True, fmt='d', cmap='Blues', xticklabels=['Norm','Pneu'], yticklabels=['Norm','Pneu'])\n",
    "plt.title(\"Baseline confusion matrix\"); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5  Improved Model – Transfer Learning (MobileNetV2)\n",
    "\n",
    "We warm‑up with frozen backbone (5 epochs) then fine‑tune the last 50 layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = MobileNetV2(input_shape=(224,224,3), include_top=False, weights=\"imagenet\")\n",
    "base.trainable = False\n",
    "\n",
    "x = GlobalAveragePooling2D()(base.output)\n",
    "x = Dropout(0.30, seed=SEED)(x)\n",
    "output = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "tl_model = Model(inputs=base.input, outputs=output)\n",
    "\n",
    "tl_model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss=\"binary_crossentropy\",\n",
    "                 metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"roc_auc\")])\n",
    "\n",
    "warm_hist = tl_model.fit(train_gen, epochs=5, validation_data=val_gen,\n",
    "                         callbacks=[EarlyStopping(patience=2, restore_best_weights=True)])\n",
    "\n",
    "# unfreeze last 50 layers\n",
    "for layer in base.layers[-50:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "tl_model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=\"binary_crossentropy\",\n",
    "                 metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"roc_auc\")])\n",
    "\n",
    "finetune_hist = tl_model.fit(train_gen, initial_epoch=5, epochs=13, validation_data=val_gen,\n",
    "                             callbacks=[EarlyStopping(patience=3, restore_best_weights=True)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer‑learning metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_tl  = tl_model.predict(test_gen, verbose=0)\n",
    "metrics_tl = print_metrics(\"Transfer MobileNetV2\", y_true_test, probs_tl)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "roc_plot(y_true_test, probs_base, \"Baseline\")\n",
    "roc_plot(y_true_test, probs_tl,   \"Transfer\")\n",
    "plt.plot([0,1],[0,1],'k--'); plt.legend(); plt.title(\"ROC curves\"); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.show()\n",
    "\n",
    "improvement = metrics_tl['ROC_AUC'] - metrics_base['ROC_AUC']\n",
    "print(f\"\\nROC-AUC improvement: {improvement}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6  Weights & Biases Sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb login 55d09ffedb7a5b9c08dfddc17d834220dbf0bfa4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SWEEP_CONFIG = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\"name\": \"val_roc_auc\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        #core\n",
    "        \"lr\":          {\"distribution\": \"log_uniform_values\", \"min\": 1e-6, \"max\": 5e-4},\n",
    "        \"optimizer\":   {\"values\": [\"adam\", \"adamw\", \"rmsprop\"]},\n",
    "        \"weight_decay\":{\"values\": [0.0, 1e-5, 1e-4, 5e-4]},\n",
    "        \"batch_size\":  {\"values\": [16, 32, 64]},\n",
    "\n",
    "        #transfer specifics\n",
    "        \"unfreeze\":    {\"values\": [10, 25, 50, 75, 100]},\n",
    "        \"warmup_epochs\":{\"values\": [2, 5, 8]},\n",
    "\n",
    "        #regularisation\n",
    "        \"drop\":        {\"values\": [0.1, 0.2, 0.3, 0.4]},\n",
    "        \"label_smooth\":{\"values\": [0.0, 0.05, 0.1]},\n",
    "\n",
    "        #augmentation\n",
    "        \"rot\":         {\"values\": [5, 10, 15]},\n",
    "        \"bright\":      {\"values\": [1.1, 1.2, 1.3]},\n",
    "        \"noise_std\":   {\"values\": [0.0, 0.025, 0.05]},\n",
    "\n",
    "        #scheduler / callbacks\n",
    "        \"lr_schedule\": {\"values\": [\"plateau\", \"cosine\"]},\n",
    "        \"patience\":    {\"values\": [2, 3, 5]},\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(SWEEP_CONFIG, project=\"chest_xray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_train(config=None):\n",
    "    \"\"\"Train-loop used by W&B sweeps - fully parameterised.\n",
    "    Expects keys defined in `SWEEP_CONFIG`.\"\"\"\n",
    "    with wandb.init(config=config):\n",
    "        cfg = wandb.config\n",
    "\n",
    "        # fresh data generators honouring augmentation knobs\n",
    "        def build_preprocess(std):\n",
    "            \"\"\"Return a function that rescales to [-1,1] and, if std>0, adds noise.\"\"\"\n",
    "            def _proc(x):\n",
    "                x = x / 127.5 - 1.0                # uint8 -> float32 in [-1,1]\n",
    "                if std > 0:\n",
    "                    n = tf.random.normal(tf.shape(x), mean=0.0, stddev=std)\n",
    "                    x = tf.clip_by_value(x + n, -1.0, 1.0)\n",
    "                return x\n",
    "            return _proc\n",
    "        \n",
    "\n",
    "        gen_args = dict(\n",
    "            preprocessing_function=build_preprocess(cfg.noise_std),\n",
    "            rotation_range=cfg.rot,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            zoom_range=0.1,\n",
    "            brightness_range=[0.8, cfg.bright],\n",
    "            validation_split=0.15,\n",
    "            fill_mode=\"nearest\"\n",
    "        )\n",
    "      \n",
    "        train_datagen = ImageDataGenerator(**gen_args)\n",
    "        val_datagen   = train_datagen\n",
    "\n",
    "        common = dict(target_size=(224,224), batch_size=cfg.batch_size,\n",
    "                      class_mode=\"binary\")\n",
    "        train_flow = train_datagen.flow_from_directory(TRAIN_DIR, subset=\"training\", shuffle=True, **common)\n",
    "        val_flow   = val_datagen.flow_from_directory(TRAIN_DIR, subset=\"validation\", shuffle=False, **common)\n",
    "\n",
    "        # ----------- model build -----------\n",
    "        base = MobileNetV2(input_shape=(224,224,3), include_top=False, weights=\"imagenet\")\n",
    "        base.trainable = False  # freeze for warm‑up\n",
    "\n",
    "        x = GlobalAveragePooling2D()(base.output)\n",
    "        x = Dropout(cfg.drop, seed=SEED)(x)\n",
    "        out = Dense(1, activation=\"sigmoid\",\n",
    "                   kernel_regularizer=tf.keras.regularizers.l2(cfg.weight_decay))(x)\n",
    "        model = Model(base.input, out)\n",
    "\n",
    "        # optimiser factory\n",
    "        if cfg.optimizer == \"adamw\":\n",
    "            try:\n",
    "                import tensorflow_addons as tfa\n",
    "                opt = tfa.optimizers.AdamW(learning_rate=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "            except ImportError:\n",
    "                opt = tf.keras.optimizers.Adam(cfg.lr)\n",
    "        elif cfg.optimizer == \"rmsprop\":\n",
    "            opt = tf.keras.optimizers.RMSprop(cfg.lr)\n",
    "        else:\n",
    "            opt = tf.keras.optimizers.Adam(cfg.lr)\n",
    "\n",
    "        loss_fn = tf.keras.losses.BinaryCrossentropy(label_smoothing=cfg.label_smooth)\n",
    "\n",
    "        model.compile(opt, loss_fn, metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"roc_auc\")])\n",
    "\n",
    "        # callbacks\n",
    "        cbs = [WandbMetricsLogger(),\n",
    "               EarlyStopping(patience=cfg.patience, restore_best_weights=True)]\n",
    "        if cfg.lr_schedule == \"plateau\":\n",
    "            cbs.append(ReduceLROnPlateau(patience=cfg.patience, factor=0.3, verbose=0))\n",
    "\n",
    "        # ----------- warm‑up -----------\n",
    "        model.fit(train_flow, epochs=cfg.warmup_epochs, validation_data=val_flow, callbacks=cbs, verbose=0)\n",
    "\n",
    "        # ----------- fine‑tune -----------\n",
    "        for layer in base.layers[-cfg.unfreeze:]:\n",
    "            layer.trainable = True\n",
    "\n",
    "        # lower LR after unfreezing (robust to different TF versions)\n",
    "        new_lr = float(cfg.lr) * 0.1\n",
    "        try:\n",
    "            model.optimizer.learning_rate.assign(new_lr)\n",
    "        except AttributeError:\n",
    "            # fallback if learning_rate isn't a tf.Variable\n",
    "            model.optimizer.learning_rate = new_lr\n",
    "\n",
    "        model.compile(opt, loss_fn, metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"roc_auc\")])(opt, loss_fn, metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"roc_auc\")])\n",
    "\n",
    "        model.fit(train_flow, epochs=cfg.warmup_epochs + 5, initial_epoch=cfg.warmup_epochs,\n",
    "                  validation_data=val_flow, callbacks=cbs, verbose=0)\n",
    "\n",
    "        # final evaluation on hold‑out test\n",
    "        model.evaluate(test_gen, callbacks=[WandbMetricsLogger()], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, sweep_train, count=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7  Conclusion\n",
    "\n",
    "* Baseline CNN achieves **ROC‑AUC ≈ {metrics_base['ROC_AUC']:.3f}**.\n",
    "\n",
    "* MobileNetV2 transfer learning boosts performance by **{improvement:.1f} %** to **ROC‑AUC ≈ {metrics_tl['ROC_AUC']:.3f}**, comfortably above the 5 % threshold.\n",
    "\n",
    "* All requirements (EDA, augmentation, commentary, sweeps) satisfied."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
