  {
   "cell_type": "markdown",
   "id": "9e556cb5",
   "metadata": {},
   "source": [
    "Assignment workflow\n",
    "Step 1. Data analysis and preparation\n",
    "Perform EDA:\n",
    "Analyze class distributions.\n",
    "Inspect examples of atypical images.\n",
    "Implement preprocessing:\n",
    "resize to 224×224;\n",
    "normalization [-1, 1];\n",
    "augmentation if possible to increase the dataset (e.g., rotation ±10°, adding noise).\n",
    "Describe and comment on the decisions in EDA.ipynb.\n",
    "Step 2. Baseline model\n",
    "Implement a simple CNN (≤ 1M parameters) in TensorFlow/Keras.\n",
    "Train the model to convergence (10–15 epochs, batch size 32).\n",
    "Record key metrics: Accuracy, Precision, Recall, F1, ROC-AUC.\n",
    "Step 3. Improved model\n",
    "Choose one of the approaches:\n",
    "Transfer learning using a pre-trained MobileNetV2.\n",
    "Deep custom CNN (at least 5 convolutional blocks) with BatchNorm and Dropout.\n",
    "Compare the metrics with the baseline and justify your choice.\n"
   ]
  },
    "plt.title('Class distribution in the training data')\n",
    "plt.ylabel('Number of images')\n",
    "plt.title('Class distribution in the validation data')\n",
    "plt.ylabel('Number of images')\n",
    "plt.title('Class distribution in the test data')\n",
    "plt.ylabel('Number of images')\n",
    "# Function to load random images from a folder\n",
    "# Load several random images from NORMAL and PNEUMONIA\n",
    "# Display the images\n",
    "fig.suptitle('Examples of images from NORMAL and PNEUMONIA classes', fontsize=16)\n",
    "print(\"Sizes and frequency:\", list(zip(unique_sizes, counts)))"
    "# Data generator for training with augmentation\n",
    "    rescale=1./127.5 - 1,  # normalization [-1; 1]\n",
    "    rotation_range=10,     # rotation ±10°\n",
    "    width_shift_range=0.1, # horizontal shift ±10%\n",
    "    height_shift_range=0.1, # vertical shift ±10%\n",
    "    horizontal_flip=False,  # horizontal flip\n",
    "    zoom_range=0.1,        # zoom ±10%\n",
    "    shear_range=0.1,       # shear\n",
    "    brightness_range=[0.8, 1.2], # brightness change\n",
    "    fill_mode='nearest'    # fill new pixels with nearest values\n",
    "# Generator for validation and test (resize and normalization only)\n",
    "# Training data generator\n",
    "# Validation data generator\n",
    "# Test data generator\n",
    "# Data generator for training with augmentation\n",
    "    rescale=1./127.5 - 1,  # normalization [-1; 1]\n",
    "    rotation_range=10,     # rotation ±10°\n",
    "    width_shift_range=0.1, # horizontal shift ±10%\n",
    "    height_shift_range=0.1, # vertical shift ±10%\n",
    "    horizontal_flip=False,  # horizontal flip\n",
    "    zoom_range=0.1,        # zoom ±10%\n",
    "    shear_range=0.1,       # shear\n",
    "    brightness_range=[0.8, 1.2], # brightness change\n",
    "    validation_split=0.15  # allocate 15% for validation from train\n",
    "# Generator for validation and test (resize and normalization only)\n",
    "# Training generator (train subset only)\n",
    "    subset='training',  # Use only a part for training\n",
    "# Validation generator (from train)\n",
    "# Use subset='validation' to obtain validation data from train\n",
    "    subset='validation' # Use only a part for validation from train\n",
    "# Test data generator\n",
    "total_images = val_generator_train.n + valid_generator.n\n",
    "print(f\"Total number of images in valid_generator: {total_images}\")"
    "# Building a simple CNN (<1M parameters)\n",
    "# Model training\n",
    "wandb.init(project='chest_x_ray', name='baseline_cnn')\n",
    "    callbacks=[WandbMetricsLogger(log_freq='epoch')]\n",
    "# Prediction on the test data\n",
    "# Key metrics\n",
    "# ROC curve\n",
    "# Confusion matrix\n",
    "### Transfer learning with pre-trained MobileNetV2\n"
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = tf.keras.applications.mobilenet_v2.preprocess_input(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "transfer_model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "transfer_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "wandb.init(project='chest_x_ray', name='mobilenet_v2_transfer')\n",
    "\n",
    "transfer_history = transfer_model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=valid_generator,\n",
    "    callbacks=[WandbMetricsLogger(log_freq='epoch')]\n",
    ")\n"
   ]
    "### Check file sizes and formats"
    "## A high number of unique image sizes (frequency = 1) may indicate photos with unusual cropping, orientation or other issues."
    "#### Preview several images of a specific size."
    "### Blur detection"
    "## Preprocessing and augmentation"
    "### Baseline CNN model"
    "### Evaluation and visualization of results"
